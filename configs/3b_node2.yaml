# Accelerate configuration for node 2 in 3-node distributed training
# This config is for the third machine (rank 2)

compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: all
machine_rank: 2  # This is node 2 (third machine)
main_process_ip: 10.1.10.51  # Replace with your main node's IP address
main_process_port: 29500
main_training_function: main
mixed_precision: bf16  # Can be 'no', 'fp16', or 'bf16'
num_machines: 3  # Total number of nodes
num_processes: 24  # Total processes across all nodes (e.g., 8 GPUs per node Ã— 3 nodes)
rdzv_backend: static  # Can also use 'c10d' for dynamic node discovery
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false

# Additional settings for multi-node training
deepspeed_config: {}  # Add DeepSpeed config here if needed 